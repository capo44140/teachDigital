/**
 * Configuration runtime pour le LLM local (LM Studio / Ollama)
 * Permet de changer le mod√®le actif depuis l'interface sans modifier le .env
 * Le mod√®le revient au d√©faut du .env au red√©marrage du serveur.
 */

const { DEFAULT_LOCAL_LLM_MODEL, LOCAL_LLM_BASE_URL } = require('../../utils/constants.js');

// Variable runtime : null = utilise le d√©faut du .env
let activeModel = null;

module.exports = {
    /**
     * Retourne le mod√®le actuellement actif
     * Priorit√© : variable runtime > env LOCAL_LLM_MODEL > constante par d√©faut
     */
    getActiveModel() {
        return activeModel || process.env.LOCAL_LLM_MODEL || DEFAULT_LOCAL_LLM_MODEL;
    },

    /**
     * Change le mod√®le actif en runtime (sans modifier le .env)
     * @param {string|null} modelId - ID du mod√®le, ou null pour revenir au d√©faut
     */
    setActiveModel(modelId) {
        activeModel = modelId;
        console.log(`üîÑ LocalLLM mod√®le actif chang√©: ${modelId || '(d√©faut .env)'}`);
    },

    /**
     * Retourne la source du mod√®le actif ('ui' si chang√© via interface, 'env' sinon)
     */
    getActiveModelSource() {
        return activeModel ? 'ui' : 'env';
    },

    /**
     * Retourne l'URL de base du LLM local
     */
    getBaseUrl() {
        return process.env.LOCAL_LLM_URL || LOCAL_LLM_BASE_URL;
    },

    /**
     * Retourne le mod√®le d√©fini dans le .env (pour le bouton "restaurer d√©faut")
     */
    getEnvModel() {
        return process.env.LOCAL_LLM_MODEL || DEFAULT_LOCAL_LLM_MODEL;
    }
};
